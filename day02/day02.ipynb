{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43540,"status":"ok","timestamp":1633957984884,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"s95ExheketBY","outputId":"cad4d908-4ce8-4c09-8100-6baa86966c77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = \"/content/drive/My Drive\"\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":442,"status":"ok","timestamp":1633958104459,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"_JvCyLxfe9nd","outputId":"b771b1f5-6802-4f32-eedb-69aafeb6b7b2"},"outputs":[{"data":{"text/plain":["['day02.ipynb',\n"," 'train_set.csv',\n"," 'test_a.csv',\n"," 'train_set.csv.zip',\n"," 'day01.ipynb']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","path = \"/content/drive/My Drive//NLP/NLP_30Days/\"\n","os.chdir(path)\n","os.listdir(path)"]},{"cell_type":"markdown","metadata":{"id":"bYNu2NlkcWuK"},"source":["### $任务3：使用 TFIDF 提取文本特征$\n","\n","1. 学习TFIDF的原理\n","\n","2. 学会使用CountVectorizer\n","\n","3. 学会使用TfidfVectorizer"]},{"cell_type":"markdown","metadata":{"id":"uQS_CRLRcWuV"},"source":["#### $TFIDF原理$"]},{"cell_type":"markdown","metadata":{"id":"BZJ5brGAcWuX"},"source":["TfidfVectorizer()基于TF-IDF算法。此算法包括两部分TF和IDF，两者相乘得到TF-IDF算法。\n","\n","TF算法统计某训练文本中，某个词的出现次数，计算公式如下：\n","\n","$$词频TF = \\frac{某个词在单个文本中出现的次数}{所有文本的总词数}$$\n","\n","IDF算法用于调整词频的权重系数，如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0.\n","\n","$$逆文档率IDF = \\frac{文本总个数}{包含改词的文本个数}$$\n","\n","sklearn中IDF的计算公式与一般书中介绍的不一样:\n","$$逆文档率IDF(X) = log\\frac{N+1}{N(x)+1} + 1 $$\n","N=训练集文本总数, N(x)=包含词x的文本数"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-MLhfyycWuZ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ML956DAHcWua"},"source":["#### $CountVectorizer的使用$"]},{"cell_type":"markdown","metadata":{"id":"7sfoprR8cWub"},"source":["Bag of Words（词袋表示），也称为Count Vectors，每个文档的字/词可以使用其出现次数来进行表示。\n","\n","在sklearn中可以直接CountVectorizer来实现这一步骤：\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjpsxgJgcWuc"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3ojzqYbcWue","outputId":"9a3bba35-9f85-4857-98e2-a56fc7dc219d"},"outputs":[{"data":{"text/plain":["['This is the first document.',\n"," 'This document is the second document.',\n"," 'And this is the third one.',\n"," 'Is this the first document?']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["corpus = [\n","    'This is the first document.',\n","    'This document is the second document.',\n","    'And this is the third one.',\n","    'Is this the first document?',\n","]\n","corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oi7O4SHJcWug"},"outputs":[],"source":["vectorizer = CountVectorizer()\n","vec_fit = vectorizer.fit_transform(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"98eXWcI9cWuh","outputId":"8cb4d404-bad8-4fd0-db85-32540baca97a"},"outputs":[{"name":"stdout","output_type":"stream","text":["语料单词及编号：\n","{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n","[('and', 0), ('document', 1), ('first', 2), ('is', 3), ('one', 4), ('second', 5), ('the', 6), ('third', 7), ('this', 8)]\n"]}],"source":["print(f'语料单词及编号：')\n","print(vectorizer.vocabulary_)\n","print(sorted(vectorizer.vocabulary_.items(),key=lambda x : x[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpg_zynNcWui","outputId":"98b655f0-7261-48a8-be02-f8fe361eecb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["每个文本含有的单词情况：\n","  (0, 8)\t1\n","  (0, 3)\t1\n","  (0, 6)\t1\n","  (0, 2)\t1\n","  (0, 1)\t1\n","  (1, 8)\t1\n","  (1, 3)\t1\n","  (1, 6)\t1\n","  (1, 1)\t2\n","  (1, 5)\t1\n","  (2, 8)\t1\n","  (2, 3)\t1\n","  (2, 6)\t1\n","  (2, 0)\t1\n","  (2, 7)\t1\n","  (2, 4)\t1\n","  (3, 8)\t1\n","  (3, 3)\t1\n","  (3, 6)\t1\n","  (3, 2)\t1\n","  (3, 1)\t1\n"]}],"source":["print(f'每个文本含有的单词情况：')\n","print(f'{vec_fit}')  #(0,8)表示第一个本文'This is the first document.'含有编号8的单词（this）个数为1,其他依次类推"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zy41v5n_cWuj","outputId":"a29fee90-4171-480b-c62e-0a0e43de16dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["文本单词频数矩阵:\n","[[0 1 1 1 0 0 1 0 1]\n"," [0 2 0 1 0 1 1 0 1]\n"," [1 0 0 1 1 0 1 1 1]\n"," [0 1 1 1 0 0 1 0 1]]\n"]}],"source":["print(f'文本单词频数矩阵:')\n","print(f'{vec_fit.toarray()}') #矩阵第一行表示含有编号1、2、3、6、8的单词频数均为1,其他依次类推"]},{"cell_type":"markdown","metadata":{"id":"tv4JUvQjcWuj"},"source":["#### $TfidfVectorizer的使用$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8s7b9l1tcWuk"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PIAMaY4rcWuk","outputId":"538e586e-9721-4316-cff1-6fcbe44c8a36"},"outputs":[{"data":{"text/plain":["['This is the first document.',\n"," 'This document is the second document.',\n"," 'And this is the third one.',\n"," 'Is this the first document?']"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["corpus = [\n","    'This is the first document.',\n","    'This document is the second document.',\n","    'And this is the third one.',\n","    'Is this the first document?',\n","]\n","corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPljjY_GcWul"},"outputs":[],"source":["tfidf  = TfidfVectorizer(norm=None)  #norm为归一化参数,norm='l2’范数时，就是对文本向量进行归一化。\n","tfidf_fit = tfidf.fit_transform(corpus)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G0XNCU2BcWul","outputId":"207aaf63-9aeb-43b9-9ddb-f94ebf99ebde"},"outputs":[{"name":"stdout","output_type":"stream","text":["语料单词及编号：\n","{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n","[('and', 0), ('document', 1), ('first', 2), ('is', 3), ('one', 4), ('second', 5), ('the', 6), ('third', 7), ('this', 8)]\n"]}],"source":["print(f'语料单词及编号：')\n","print(f'{tfidf.vocabulary_}')\n","print(f'{sorted(tfidf.vocabulary_.items(),key=lambda x : x[1])}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPqqXqhWcWum","outputId":"9ab4debb-486f-4e5d-84f8-aff1e908f930"},"outputs":[{"name":"stdout","output_type":"stream","text":["IDF值：\n","[1.916 1.223 1.511 1.    1.916 1.916 1.    1.916 1.   ]\n","(9,)\n"]}],"source":["import numpy as np\n","print(f'IDF值：')\n","print(f'{np.round(tfidf.idf_,3)}')\n","print(f'{tfidf.idf_.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvS1eEhVcWum","outputId":"1cebdfa7-620f-4e92-f5ca-0cd33fef6a7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["TF-IDF值：\n","[[0.    1.223 1.511 1.    0.    0.    1.    0.    1.   ]\n"," [0.    2.446 0.    1.    0.    1.916 1.    0.    1.   ]\n"," [1.916 0.    0.    1.    1.916 0.    1.    1.916 1.   ]\n"," [0.    1.223 1.511 1.    0.    0.    1.    0.    1.   ]]\n"]}],"source":["print(f'TF-IDF值：')\n","print(f'{np.round(tfidf_fit.toarray(),3)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNTpSgefcWum","outputId":"14d0703c-e7a9-4234-8c33-d345daa384b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["TF矩阵：\n","[[0 1 1 1 0 0 1 0 1]\n"," [0 2 0 1 0 1 1 0 1]\n"," [1 0 0 1 1 0 1 1 1]\n"," [0 1 1 1 0 0 1 0 1]]\n"]}],"source":["print(f'TF矩阵：')\n","print(f'{vec_fit.toarray()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NEo1I_7cWun","outputId":"e062b6d3-ba8e-4907-c223-835e02171bdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["计算document的idf值：\n","1.2231435513142097\n"]}],"source":["print(f'计算 document 的idf值：')\n","print(f'{np.log((4+1)/(3+1))+1}') #包含document的文本有3个，总文本数为4个，根据idf公式计算"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nQZlL-scWun","outputId":"f0756ae1-d56e-40be-dce0-8ee131e099db"},"outputs":[{"name":"stdout","output_type":"stream","text":["计算tf * idf:\n","[[0.    1.223 1.511 1.    0.    0.    1.    0.    1.   ]\n"," [0.    2.446 0.    1.    0.    1.916 1.    0.    1.   ]\n"," [1.916 0.    0.    1.    1.916 0.    1.    1.916 1.   ]\n"," [0.    1.223 1.511 1.    0.    0.    1.    0.    1.   ]]\n"]}],"source":["print(f'计算tf * idf:')\n","print(f'{vec_fit.toarray() * np.round(tfidf.idf_,3 )}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMy70QbTcWuo"},"outputs":[],"source":["#选择norm='l2'对文本向量进行归一化\n","tfidf_l2 = TfidfVectorizer(norm='l2')\n","tfidf_l2_fit = tfidf_l2.fit_transform(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKC_SrZLcWuo","outputId":"6b170a4b-3009-4ca5-904f-25a8d7d959d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.916 1.223 1.511 1.    1.916 1.916 1.    1.916 1.   ]\n"]}],"source":["print(f'{np.round(tfidf_l2.idf_,3)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9tV-kRecWuo","outputId":"a94a9d12-c1d6-491b-8853-d701eac5f02c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.    0.47  0.58  0.384 0.    0.    0.384 0.    0.384]\n"," [0.    0.688 0.    0.281 0.    0.539 0.281 0.    0.281]\n"," [0.512 0.    0.    0.267 0.512 0.    0.267 0.512 0.267]\n"," [0.    0.47  0.58  0.384 0.    0.    0.384 0.    0.384]]\n"]}],"source":["print(f'{np.round(tfidf_l2_fit.toarray(),3)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpCxnw0ccWup","outputId":"687c44b4-11c6-48ce-89f5-96395a4d7308"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 1 1 1 0 0 1 0 1]\n"," [0 2 0 1 0 1 1 0 1]\n"," [1 0 0 1 1 0 1 1 1]\n"," [0 1 1 1 0 0 1 0 1]]\n"]}],"source":["print(f'{vec_fit.toarray()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFNpJNCFcWup","outputId":"46e74648-fbef-4a5d-bbad-2f936337c57a"},"outputs":[{"name":"stdout","output_type":"stream","text":["  (0, 1)\t0.46979138557992045\n","  (0, 2)\t0.5802858236844359\n","  (0, 6)\t0.38408524091481483\n","  (0, 3)\t0.38408524091481483\n","  (0, 8)\t0.38408524091481483\n","  (1, 5)\t0.5386476208856763\n","  (1, 1)\t0.6876235979836938\n","  (1, 6)\t0.281088674033753\n","  (1, 3)\t0.281088674033753\n","  (1, 8)\t0.281088674033753\n","  (2, 4)\t0.511848512707169\n","  (2, 7)\t0.511848512707169\n","  (2, 0)\t0.511848512707169\n","  (2, 6)\t0.267103787642168\n","  (2, 3)\t0.267103787642168\n","  (2, 8)\t0.267103787642168\n","  (3, 1)\t0.46979138557992045\n","  (3, 2)\t0.5802858236844359\n","  (3, 6)\t0.38408524091481483\n","  (3, 3)\t0.38408524091481483\n","  (3, 8)\t0.38408524091481483\n"]}],"source":["print(f'{tfidf_l2_fit}')"]},{"cell_type":"markdown","metadata":{"id":"bcSuqgkMcWup"},"source":["### $任务4：使用 TFIDF 特征 和 线性模型完成训练和预测$\n","\n","1. 使用TFIDF提取训练集和测试集特征\n","\n","2. 使用线性模型（LR等）完成模型的训练和预测"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1633959383413,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"56qfJpGWeZc7"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import RidgeClassifier,LogisticRegression\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score,accuracy_score\n","import pandas as pd"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1633958150896,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"wU9ynYv_eBqQ"},"outputs":[],"source":["train_df = pd.read_csv('./train_set.csv', sep='\\t')\n","test_df = pd.read_csv('./test_a.csv', sep='\\t')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":408,"status":"ok","timestamp":1633958163754,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"g_QuWONWftaj","outputId":"26cdb5b4-b6d9-4cf6-c6e3-2f769d1bb029"},"outputs":[{"data":{"text/plain":["(200000, 2)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1633958171242,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"Fwn-15aKfvoq","outputId":"26bb46d5-a492-4ec1-b3b8-e2e77d708fee"},"outputs":[{"data":{"text/plain":["(50000, 1)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["test_df.shape"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":408,"status":"ok","timestamp":1633958198325,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"9SgrO6lJd5FH","outputId":"2d76286d-3df4-4cb3-e8b0-f60bd30282b5"},"outputs":[{"data":{"text/plain":["(250000,)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_text = train_df['text']\n","test_text = test_df['text']\n","all_text = pd.concat([train_text, test_text])\n","all_text.shape"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244984,"status":"ok","timestamp":1633958625654,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"Loj_D3e0f-7M","outputId":"7db5a17d-a510-4216-cb21-aff101fc8e52"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4min 3s, sys: 1.43 s, total: 4min 4s\n","Wall time: 4min 4s\n"]}],"source":["%%time\n","tfidf = TfidfVectorizer(\n","    sublinear_tf=True,\n","    strip_accents='unicode',\n","    analyzer='word',\n","    token_pattern=r'\\w{1,}',\n","    stop_words='english',\n","    ngram_range=(1,1),\n","    max_features=10000)\n","\n","tfidf_fit = tfidf.fit(all_text)\n","train_word_features = tfidf_fit.transform(train_text)\n","test_word_features = tfidf_fit.transform(test_text)\n","train_word_features"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":410,"status":"ok","timestamp":1633958746149,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"RAKQfurvgjaV"},"outputs":[],"source":["#准备训练集、验证集与测试集\n","X_train = train_word_features\n","y_train = train_df['label']\n","\n","#切分训练集与验证集\n","x_train_, x_valid_, y_train_, y_valid_ = train_test_split(X_train, y_train, test_size=0.2)\n","X_test = test_word_features"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":131230,"status":"ok","timestamp":1633959005707,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"-wjruniWg2y5","outputId":"bbc982ef-461b-4011-e4ea-846b88e90459"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.94926875 0.917841513930204\n","CPU times: user 1.57 s, sys: 937 ms, total: 2.51 s\n","Wall time: 2min 10s\n"]}],"source":["#TF-IDF + LR\n","%%time\n","clf = LogisticRegression(C=4, n_jobs=16) #设置惩罚项C=4\n","clf.fit(x_train_, y_train_)\n","\n","y_pred = clf.predict(x_valid_)\n","train_scores = clf.score(x_train_, y_train_)\n","print(train_scores, f1_score(y_pred, y_valid_, average='macro'))"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110613,"status":"ok","timestamp":1633959578307,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"cj4fOfiEcWuq","outputId":"f0be74f1-faf2-4197-e71d-edf710f5a14a"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9237375 0.8912840859180118\n"]}],"source":["#TF-IDF + Ridge\n","%%time\n","clf = RidgeClassifier(alpha=4)\n","clf.fit(x_train_, y_train_)\n","\n","y_pred = clf.predict(x_valid_)\n","train_scores = clf.score(x_train_, y_train_)\n","print(train_scores, f1_score(y_pred, y_valid_, average='macro'))"]},{"cell_type":"markdown","metadata":{"id":"LMu0fp9lcWur"},"source":["### $任务5：使用 TFIDF 特征 和 XGBoost完成训练和预测$\n","\n","1. 使用TFIDF提取训练集和测试集特征\n","\n","2. 使用XGBoost完成模型的训练和预测"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":502,"status":"ok","timestamp":1633959730093,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"6NTB2rUdcWur"},"outputs":[],"source":["#TF-IDF + XGBOOST\n","from xgboost.sklearn import XGBClassifier"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":402,"status":"ok","timestamp":1633959913544,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"MDKq9Po8cWus"},"outputs":[],"source":["class XGB():\n","\n","  def __init__(self, X_df, y_df):\n","    self.X = X_df\n","    self.y = y_df\n","      \n","  def train(self, param):\n","    self.model = XGBClassifier(**param)\n","    self.model.fit(self.X, self.y, eval_set=[(self.X, self.y)],\n","            eval_metric=['mlogloss'],\n","            early_stopping_rounds=10,  # 连续N次分值效果没有提升，则停止训练\n","            verbose=False\n","            )\n","      \n","  # mode evaluation\n","    train_result, train_proba = self.model.predict(self.X), self.model.predict_proba(self.X)\n","    train_acc = accuracy_score(self.y, train_result)\n","    train_auc = f1_score(self.y, train_proba, average='macro')\n","    \n","    print(\"Train acc: %.2f%% Train auc: %.2f\" % (train_acc*100.0, train_auc))\n","      \n","  def test(self, X_test, y_test):\n","    result, proba = self.model.predict(X_test), self.model.predict_proba(X_test)\n","    acc = accuracy_score(y_test, result)\n","    f1 = f1_score(y_test, proba, average='macro')\n","    \n","    print(\"acc: %.2f%% F1_score: %.2f%%\" % (acc*100.0, f1))\n","\n","  def grid(self, param_grid):\n","    self.param_grid = param_grid\n","    xgb_model = XGBClassifier(nthread=20)\n","    clf = GridSearchCV(xgb_model, self.param_grid, scoring='f1_macro', cv=2, verbose=1)\n","    clf.fit(self.X, self.y)\n","    print(\"Best score: %f using parms: %s\" % (clf.best_score_, clf.best_params_))\n","    return clf.best_params_, clf.best_score_\n"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":400,"status":"ok","timestamp":1633959949943,"user":{"displayName":"Nan Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00534318286128940321"},"user_tz":-480},"id":"slK0vzhpcWus"},"outputs":[],"source":["# 选取前500特征入模型\n","x_train_, x_valid_, y_train_, y_valid_ = train_test_split(X_train[:, :500], y_train, test_size=0.2, shuffle=True, random_state=42)\n","X_test = test_word_features[:,:500]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Z0Wd4OxkblQ"},"outputs":[],"source":["%%time\n","param = {'learning_rate': 0.05, #(xgb’s “eta”)\n","      'objective': 'multi:softmax', \n","      'n_jobs': 16,\n","      'n_estimators': 300, #树的个数\n","      'max_depth': 10,               \n","      'gamma': 0.5,   #惩罚项中叶子结点个数前的参数，Increasing this value will make model more conservative.\n","      'reg_alpha': 0,  #L1 regularization term on weights.Increasing this value will make model more conservative.\n","      'reg_lambda': 2,  #L2 regularization term on weights.Increasing this value will make model more conservative.\n","      'min_child_weight' : 1, #叶子节点最小权重\n","      'subsample':0.8,     #随机选择80%样本建立决策树\n","      'random_state':1     #随机数\n","      }\n","model = XGB(x_train_, y_train_)\n","model.train(param)\n","model.test(x_valid_, y_valid_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rwwr1P-DkbXd"},"outputs":[],"source":["xgb_model = XGB(X_train, y_train)\n","xgb_model.train(param)\n","\n","submission = pd.read_csv('./test_a_sample_submit.csv')\n","preds = xgb_model.model.predict(X_test)\n","submission['label'] = preds\n","submission.to_csv('./xgb_submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6yppTbWkaeY"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"day02.ipynb","provenance":[]},"interpreter":{"hash":"0b44c525ca95e5dbf893da2282eb3ec3f420cb9fa59d94f9af90ca833dc1a37c"},"kernelspec":{"display_name":"Python 3.7.10 64-bit ('pytorch': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
